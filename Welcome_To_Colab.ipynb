{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saijagadeeshsistla/Python_ML_AI-/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "SAP Sales Forecasting — End‑to‑End Python Script\n",
        "\n",
        "What it does\n",
        "------------\n",
        "1) Loads SAP sales data from CSV/Excel (exported from SAP SD/MM/HANA views)\n",
        "2) Cleans and aggregates to a time series (daily/weekly/monthly)\n",
        "3) Builds features (lags, rolling means, calendar flags)\n",
        "4) Trains a time-aware model (RandomForest) on past data\n",
        "5) Generates H-step forecasts with backtesting metrics (RMSE, MAPE)\n",
        "6) Saves a forecast CSV and (optionally) plots actual vs. forecast\n",
        "\n",
        "Usage (examples)\n",
        "----------------\n",
        "python sap_sales_forecast.py --input ./sap_sales.csv --date_col DocumentDate \\\n",
        "  --qty_col Quantity --material_col Material --group_by Material \\\n",
        "  --material_id 10001234 --freq M --horizon 6 --plot\n",
        "\n",
        "Minimal usage (aggregate all sales):\n",
        "python sap_sales_forecast.py --input ./sap_sales.csv --date_col DocumentDate --qty_col NetValue --freq M --horizon 6\n",
        "\n",
        "Input expectations\n",
        "------------------\n",
        "- CSV/Excel should have at least a date column and a numeric measure (quantity or value).\n",
        "- Optional columns for filtering: Material, Plant, SalesOrg, etc.\n",
        "\n",
        "Notes\n",
        "-----\n",
        "- Designed to work with standard libraries available in most Python envs (pandas, numpy, scikit-learn, statsmodels optional for diagnostics not required).\n",
        "- If you have HANA access, you can replace the loader with a SQL query (template included below, commented out).\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "try:\n",
        "    import matplotlib.pyplot as plt  # Only used if --plot is given\n",
        "except Exception:  # pragma: no cover\n",
        "    plt = None\n",
        "\n",
        "# -----------------------------\n",
        "# Utility functions\n",
        "# -----------------------------\n",
        "\n",
        "def parse_args():\n",
        "    p = argparse.ArgumentParser(description=\"SAP Sales Forecasting\")\n",
        "    p.add_argument(\"--input\", required=True, help=\"Path to SAP export file (.csv or .xlsx)\")\n",
        "    p.add_argument(\"--sheet\", default=None, help=\"Excel sheet name if .xlsx\")\n",
        "    p.add_argument(\"--date_col\", required=True, help=\"Column with document/posting date\")\n",
        "    p.add_argument(\"--qty_col\", required=True, help=\"Numeric column to forecast (e.g., Quantity or NetValue)\")\n",
        "    p.add_argument(\"--group_by\", default=None, help=\"Column to group by (e.g., Material)\")\n",
        "    p.add_argument(\"--material_col\", default=None, help=\"Alias for --group_by if clearer\")\n",
        "    p.add_argument(\"--material_id\", default=None, help=\"Value within group_by to filter (e.g., SKU code)\")\n",
        "    p.add_argument(\"--plant\", default=None, help=\"Filter by Plant code (optional)\")\n",
        "    p.add_argument(\"--plant_col\", default=\"Plant\", help=\"Column name for Plant (optional)\")\n",
        "    p.add_argument(\"--freq\", default=\"M\", choices=[\"D\",\"W\",\"M\"], help=\"Resample frequency: D/W/M\")\n",
        "    p.add_argument(\"--horizon\", type=int, default=6, help=\"Forecast horizon in periods of --freq\")\n",
        "    p.add_argument(\"--min_periods\", type=int, default=24, help=\"Minimum periods required to train\")\n",
        "    p.add_argument(\"--plot\", action=\"store_true\", help=\"Plot actual vs forecast\")\n",
        "    p.add_argument(\"--output\", default=\"forecast_output.csv\", help=\"Path to save forecast CSV\")\n",
        "    return p.parse_args()\n",
        "\n",
        "\n",
        "def load_data(path: str, sheet: Optional[str] = None) -> pd.DataFrame:\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext == \".csv\":\n",
        "        df = pd.read_csv(path)\n",
        "    elif ext in (\".xlsx\", \".xls\"):\n",
        "        df = pd.read_excel(path, sheet_name=sheet or 0)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format: use .csv or .xlsx\")\n",
        "    return df\n",
        "\n",
        "\n",
        "# HANA/Database template (optional)\n",
        "# ---------------------------------\n",
        "# import sqlalchemy as sa\n",
        "# def load_from_hana(conn_str: str, sql: str) -> pd.DataFrame:\n",
        "#     eng = sa.create_engine(conn_str)\n",
        "#     with eng.connect() as cx:\n",
        "#         return pd.read_sql(sql, cx)\n",
        "# Example conn_str: 'hana+pyhdb://USER:PASSWORD@host:30015'\n",
        "# Example sql: SELECT BILL_DATE as DocumentDate, MATERIAL as Material, NET_VALUE as NetValue FROM SALES_VIEW\n",
        "\n",
        "\n",
        "def prepare_timeseries(df: pd.DataFrame,\n",
        "                       date_col: str,\n",
        "                       y_col: str,\n",
        "                       freq: str = \"M\",\n",
        "                       group_by: Optional[str] = None,\n",
        "                       group_val: Optional[str] = None,\n",
        "                       plant_col: Optional[str] = None,\n",
        "                       plant: Optional[str] = None) -> pd.Series:\n",
        "    # Standardize column names via direct references\n",
        "    d = df.copy()\n",
        "\n",
        "    # Filter by plant if requested\n",
        "    if plant and plant_col and plant_col in d.columns:\n",
        "        d = d[d[plant_col].astype(str) == str(plant)]\n",
        "\n",
        "    # Filter by group (e.g., specific Material)\n",
        "    gb_col = group_by\n",
        "    if gb_col is None and group_val is not None:\n",
        "        raise ValueError(\"Provide --group_by/--material_col when using --material_id\")\n",
        "    if group_by is None and plant is None:\n",
        "        pass\n",
        "\n",
        "    if gb_col and gb_col not in d.columns:\n",
        "        raise ValueError(f\"group_by column '{gb_col}' not found in data\")\n",
        "\n",
        "    if gb_col and group_val is not None:\n",
        "        d = d[d[gb_col].astype(str) == str(group_val)]\n",
        "\n",
        "    # Parse dates and coerce numeric\n",
        "    if date_col not in d.columns:\n",
        "        raise ValueError(f\"date_col '{date_col}' not found in data\")\n",
        "    if y_col not in d.columns:\n",
        "        raise ValueError(f\"qty_col '{y_col}' not found in data\")\n",
        "\n",
        "    d[date_col] = pd.to_datetime(d[date_col], errors='coerce')\n",
        "    d = d.dropna(subset=[date_col])\n",
        "\n",
        "    d[y_col] = pd.to_numeric(d[y_col], errors='coerce')\n",
        "    d = d.dropna(subset=[y_col])\n",
        "\n",
        "    # Aggregate to daily, then resample\n",
        "    daily = (d.groupby(d[date_col].dt.to_period('D'))[y_col]\n",
        "               .sum()\n",
        "               .to_timestamp())\n",
        "\n",
        "    ts = daily.resample(freq).sum().fillna(0.0)\n",
        "    ts.name = y_col\n",
        "    return ts\n",
        "\n",
        "\n",
        "def build_features(ts: pd.Series) -> pd.DataFrame:\n",
        "    df = ts.to_frame(name='y').copy()\n",
        "    df['t'] = np.arange(len(df))\n",
        "    # Calendar features\n",
        "    idx = df.index\n",
        "    df['year'] = idx.year\n",
        "    df['month'] = idx.month\n",
        "    df['week'] = getattr(idx, 'isocalendar').week if hasattr(getattr(idx, 'isocalendar', None), 'week') else getattr(idx, 'week', 0)\n",
        "    df['quarter'] = idx.quarter\n",
        "\n",
        "    # Lag features (handle frequency-agnostic with 1, 2, 3, 6, 12 periods)\n",
        "    for L in [1, 2, 3, 6, 12]:\n",
        "        df[f'lag_{L}'] = df['y'].shift(L)\n",
        "    # Rolling means\n",
        "    for W in [3, 6, 12]:\n",
        "        df[f'roll_mean_{W}'] = df['y'].shift(1).rolling(W).mean()\n",
        "        df[f'roll_std_{W}'] = df['y'].shift(1).rolling(W).std()\n",
        "\n",
        "    df = df.dropna()\n",
        "    return df\n",
        "\n",
        "\n",
        "def time_split(df: pd.DataFrame, horizon: int) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    if len(df) <= horizon:\n",
        "        raise ValueError(\"Not enough history; reduce horizon or collect more data\")\n",
        "    train = df.iloc[:-horizon]\n",
        "    test = df.iloc[-horizon:]\n",
        "    return train, test\n",
        "\n",
        "\n",
        "def fit_model(train: pd.DataFrame) -> RandomForestRegressor:\n",
        "    X = train.drop(columns=['y'])\n",
        "    y = train['y']\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=400,\n",
        "        max_depth=None,\n",
        "        min_samples_split=3,\n",
        "        min_samples_leaf=1,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    model.fit(X, y)\n",
        "    return model\n",
        "\n",
        "\n",
        "def evaluate(model, test: pd.DataFrame) -> Tuple[float, float]:\n",
        "    X_test = test.drop(columns=['y'])\n",
        "    y_true = test['y']\n",
        "    y_pred = model.predict(X_test)\n",
        "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
        "    mape = float(np.mean(np.abs((y_true - y_pred) / np.clip(np.abs(y_true), 1e-8, None))) * 100)\n",
        "    return rmse, mape\n",
        "\n",
        "\n",
        "def iterative_forecast(model: RandomForestRegressor, ts: pd.Series, horizon: int) -> pd.Series:\n",
        "    history = ts.copy()\n",
        "    forecasts = []\n",
        "    freq = ts.index.freq or pd.infer_freq(ts.index) or 'M'\n",
        "\n",
        "    for i in range(horizon):\n",
        "        feats = build_features(history).iloc[[-1]].drop(columns=['y'])\n",
        "        y_hat = float(model.predict(feats)[0])\n",
        "        next_idx = (history.index[-1] + pd.tseries.frequencies.to_offset(freq))\n",
        "        history.loc[next_idx] = y_hat\n",
        "        forecasts.append((next_idx, y_hat))\n",
        "\n",
        "    fc = pd.Series({idx: val for idx, val in forecasts})\n",
        "    fc.name = 'forecast'\n",
        "    return fc\n",
        "\n",
        "\n",
        "def run_pipeline(args):\n",
        "    df = load_data(args.input, args.sheet)\n",
        "\n",
        "    group_by = args.group_by or args.material_col\n",
        "\n",
        "    ts = prepare_timeseries(\n",
        "        df,\n",
        "        date_col=args.date_col,\n",
        "        y_col=args.qty_col,\n",
        "        freq=args.freq,\n",
        "        group_by=group_by,\n",
        "        group_val=args.material_id,\n",
        "        plant_col=args.plant_col,\n",
        "        plant=args.plant,\n",
        "    )\n",
        "\n",
        "    if len(ts) < args.min_periods:\n",
        "        raise ValueError(f\"Need at least {args.min_periods} periods; found {len(ts)}\")\n",
        "\n",
        "    feat_df = build_features(ts)\n",
        "    train, test = time_split(feat_df, args.horizon)\n",
        "    model = fit_model(train)\n",
        "\n",
        "    rmse, mape = evaluate(model, test)\n",
        "    print(f\"Backtest — RMSE: {rmse:.2f}, MAPE: {mape:.2f}% (horizon={args.horizon})\")\n",
        "\n",
        "    # Refit on full history for final forecast\n",
        "    model = fit_model(feat_df)\n",
        "    fc = iterative_forecast(model, ts, args.horizon)\n",
        "\n",
        "    out = pd.DataFrame({\n",
        "        'actual': ts,\n",
        "        'forecast': fc\n",
        "    })\n",
        "\n",
        "    # Align index and write CSV\n",
        "    out.index.name = 'Period'\n",
        "    out.to_csv(args.output)\n",
        "    print(f\"Saved forecast to: {os.path.abspath(args.output)}\")\n",
        "\n",
        "    if args.plot:\n",
        "        if plt is None:\n",
        "            print(\"matplotlib not available; skipping plot\")\n",
        "        else:\n",
        "            plt.figure(figsize=(10,5))\n",
        "            ts.plot(label='Actual')\n",
        "            fc.plot(label='Forecast')\n",
        "            plt.title('SAP Sales: Actual vs Forecast')\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # If run as a script via the canvas, you can simulate CLI by editing below\n",
        "    if len(sys.argv) == 1:\n",
        "        print(\"Tip: supply --input, --date_col, --qty_col. See header for examples.\")\n",
        "    args = parse_args()\n",
        "    run_pipeline(args)"
      ],
      "metadata": {
        "id": "YUoTUd95MmFH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}